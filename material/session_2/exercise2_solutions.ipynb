{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** In most sessions you will be solving exercises posed in a Jupyter notebook that looks like this one. Because you are cloning a Github repository that only we can push to, you should **NEVER EDIT** any of the files you pull from Github. Instead, what you should do, is either make a new notebook and write your solutions in there, or **make a copy of this notebook and save it somewhere else** on your computer, not inside the `sds` folder that you cloned, so you can write your answers in there. If you edit the notebook you pulled from Github, those edits (possible your solutions to the exercises) may be overwritten and lost the next time you pull from Github. This is important, so don't hesitate to ask if it is unclear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Set 2: Breast cancer\n",
    "\n",
    "*February 14, 2020*\n",
    "\n",
    "In this Exercise Set 2 we will work with the Breast Cancer dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T23:26:00.234214Z",
     "start_time": "2020-02-16T23:26:00.203052Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>benign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension   ...    worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871   ...            17.33           184.60      2019.0   \n",
       "1                 0.05667   ...            23.41           158.80      1956.0   \n",
       "2                 0.05999   ...            25.53           152.50      1709.0   \n",
       "3                 0.09744   ...            26.50            98.87       567.7   \n",
       "4                 0.05883   ...            16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  benign  \n",
       "0          0.4601                  0.11890     0.0  \n",
       "1          0.2750                  0.08902     0.0  \n",
       "2          0.3613                  0.08758     0.0  \n",
       "3          0.6638                  0.17300     0.0  \n",
       "4          0.2364                  0.07678     0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "raw_data = load_breast_cancer()\n",
    "data_features = pd.DataFrame(\n",
    "    np.hstack([raw_data['data'], raw_data['target'].reshape(-1, 1)]),\n",
    "    columns=raw_data['feature_names'].tolist() + ['benign']\n",
    ")\n",
    "data_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract X and y**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T23:26:04.066549Z",
     "start_time": "2020-02-16T23:26:04.063714Z"
    }
   },
   "outputs": [],
   "source": [
    "X = raw_data['data']\n",
    "y = raw_data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 2.1.1**: The performance of a random forest classifier is highly sensitive to hyper parameters. Therefore, you should be intimately familiar with what the most important ones do. For each point below, explain what the hyper parameter pertaining to `sklearn.ensemble.RandomForestClassifier` controls, and how setting it either too low or too high (or True/False) might hurt model performance:\n",
    "1. `n_estimators`\n",
    "2. `max_depth`\n",
    "3. `max_features`\n",
    "4. `bootstrap`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This question will be in assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 2.1.2**: For `n_estimators > 1`how should one set the hyper-parameters `max_features` and `bootstrap` so that all the trees in the ensemble end up identical?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This question will be in assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 2.1.3**: Plot training and test accuracy of the random forest classifier as a function of `n_estimators`. Also indicate with a horizontal line (e.g. use `plt.axhline`) where the baseline accuracy lies (always guessing for majority class). Comparing and training and test performance, can you say something abotu how your model performs? And how does it perform relative to baseline? Report your maximum testing accuracy.\n",
    ">\n",
    "> *Hints: Use `StratifiedShuffleSplit` with the `cross_validate` method and give the latter the argument `return_train_score=True` to assess both training and test scores during cross validation. Also, you could let `n_estimators` vary on a logarithmic scale (like `np.logspace(np.log10(5), np.log10(500), 20)`) and log-scale the x-axis in your plot (`plt.xscale('log')`).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This question will be in assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 2.2.1**: Repeat Ex. 2.1.3, but using AdaBoost. Do you notice any performance difference?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T21:57:46.326706Z",
     "start_time": "2020-02-16T21:57:46.321667Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T22:07:04.468256Z",
     "start_time": "2020-02-16T22:02:57.647158Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [04:06<00:00, 12.34s/it]\n"
     ]
    }
   ],
   "source": [
    "train_acc, test_acc = [], []\n",
    "param_range = np.logspace(np.log10(50), np.log10(500), 20)\n",
    "for param in tqdm(param_range):\n",
    "\n",
    "    model = AdaBoostClassifier(n_estimators=int(param))\n",
    "    #cv = ShuffleSplit(n_splits=20, test_size=.05, random_state=3)\n",
    "    cv = KFold(n_splits=20)\n",
    "    \n",
    "    # accuracies\n",
    "    scores = cross_validate(model, X, y, cv=cv, return_train_score=True)\n",
    "    train_acc.append(np.mean(scores['train_score']))\n",
    "    test_acc.append(np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T22:07:10.029207Z",
     "start_time": "2020-02-16T22:07:09.783038Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(param_range, train_acc, label=\"training accuracy\")\n",
    "plt.plot(param_range, test_acc, label=\"testing accuracy\")\n",
    "plt.axhline(sum(y) / len(y), ls=\"--\", label=\"baseline\")\n",
    "#plt.ylim(0.81, 0.9)\n",
    "plt.xlabel(\"`param`\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T22:08:18.021129Z",
     "start_time": "2020-02-16T22:08:18.016859Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9754926108374387"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost is 1.5 percent points more accurate!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 2.2.1**: Repeat Ex. 2.1.3, but using `sklearn.ensemble.GradientBoostingClassifier`. Do you notice any performance difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T08:05:57.081880Z",
     "start_time": "2020-02-17T08:05:57.078717Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T08:18:10.449757Z",
     "start_time": "2020-02-17T08:16:18.798314Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [01:51<00:00,  5.58s/it]\n"
     ]
    }
   ],
   "source": [
    "train_acc, test_acc = [], []\n",
    "param_range = np.logspace(np.log10(50), np.log10(1000), 20)\n",
    "for param in tqdm(param_range):\n",
    "\n",
    "    model = GradientBoostingClassifier(n_estimators=int(param), max_depth=1, subsample=0.5)\n",
    "    #cv = ShuffleSplit(n_splits=20, test_size=.05, random_state=3)\n",
    "    cv = KFold(n_splits=20)\n",
    "    \n",
    "    # accuracies\n",
    "    scores = cross_validate(model, X, y, cv=cv, return_train_score=True)\n",
    "    train_acc.append(np.mean(scores['train_score']))\n",
    "    test_acc.append(np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T08:18:13.435832Z",
     "start_time": "2020-02-17T08:18:13.164378Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(param_range, train_acc, label=\"training accuracy\")\n",
    "plt.plot(param_range, test_acc, label=\"testing accuracy\")\n",
    "plt.axhline(sum(y) / len(y), ls=\"--\", label=\"baseline\")\n",
    "#plt.ylim(0.81, 0.9)\n",
    "plt.xlabel(\"`param`\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T08:18:16.456701Z",
     "start_time": "2020-02-17T08:18:16.450821Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9807881773399016"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can up the performance slightly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you will be manually implementing the decision tree mechanism across a number of connected exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Ex. 2.3.1**: Find the best feature to split on. There are many ways to do this, and we will be very practical about this and use the Pearson correlatio coefficient between a feature and the outcome, as an indicator of goodness.\n",
    "Therefore, write a function that takes your input data `data_features` as input and returns the name of the feature that has the highest absolute (positive or negative) correlation with the outcome.\n",
    "Use this function on your data to find the best initial feature to split on.\n",
    ">\n",
    "> *Hint: You can use `scipy.stats.pearsonr` to compute the correlation coefficient. E.g. to compute the absolute correlation coefficient between two variables `a` and `b`, I would write `abs(pearsonr(a, b)[0])`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T07:19:04.301222Z",
     "start_time": "2020-02-17T07:19:04.296878Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "def best_feature(data):\n",
    "    correlations = []\n",
    "    for feature in data_features.columns[:-1]:\n",
    "        correlations.append(\n",
    "            abs(spearmanr(data[feature], data['benign'])[0])\n",
    "        )\n",
    "    top_i = np.argmax(correlations)\n",
    "    return data_features.columns[top_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T07:19:05.027595Z",
     "start_time": "2020-02-17T07:19:04.991580Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'worst perimeter'"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_feature(data_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Ex. 2.3.2**: Read about [Shannon entropy](https://en.wikipedia.org/wiki/Entropy_(information_theory)). Write a function that computes the Shannon-entropy of a probability vector. Compute the Shannon entropy of `p=[0.4, 0.6]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T22:14:47.857897Z",
     "start_time": "2020-02-16T22:14:47.852393Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def shannon_entropy(p):\n",
    "    return - sum([p_ * np.log2(p_) for p_ in p])\n",
    "\n",
    "shannon_entropy([0.4, 0.6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Ex. 2.3.3**: Compute split entropy. \n",
    "1. Write a function `split_data_on(data, feature, thr)` that takes as input your data, initially `data_features`, a threshold, `thr`, and a feature, `feature`, and then splits the data into two subsets (also `pandas.Dataframe`s), `data0` and `data1`, where samples in `data0` have `data[feature] > thr` and samples in `data1` have `data[feature] > thr`. Use it to split `data_features` on the 'worst perimeter' feature at 105.9, to create two new variables `data0` and `data1` and print their number of rows.\n",
    "1. Write another function `outcome_entropy(data)` that computes the entropy of outcomes ('benign' column), given a subset. Print the entropies of `data0` and `data1`.\n",
    "2. Write a final function `split_entropy(data0, data1)` that uses the previous function to compute the split entropy (i.e. weighted average of both resulting subsets). Compute the split entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T07:21:44.769624Z",
     "start_time": "2020-02-17T07:21:44.763814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345 224\n"
     ]
    }
   ],
   "source": [
    "def split_data_on(data, feature, thr):\n",
    "    \"\"\"Function that splits the data on the given feature and\n",
    "    returns two new datasets.\n",
    "    \"\"\"\n",
    "    mask = data[feature] > thr\n",
    "    return data[~mask], data[ mask]\n",
    "\n",
    "data0, data1 = split_data_on(data_features, 'worst perimeter', 105.9)\n",
    "print(data0.shape[0], data1.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T07:21:45.342244Z",
     "start_time": "2020-02-17T07:21:45.337413Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2833107377061481\n",
      "0.5559671540224538\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def outcome_entropy(datai):\n",
    "    def _probability_dist_of_labels(list_of_labels):\n",
    "        label_counts = Counter(list_of_labels)\n",
    "        return [v/sum(label_counts.values()) for k, v in label_counts.items()]\n",
    "    return shannon_entropy(_probability_dist_of_labels(datai['benign']))\n",
    "\n",
    "print(outcome_entropy(data0))\n",
    "print(outcome_entropy(data1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T07:21:45.887670Z",
     "start_time": "2020-02-17T07:21:45.881422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39064823727530884"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_entropy(data0, data1):\n",
    "    # Compute entropies\n",
    "    ent0 = outcome_entropy(data0)\n",
    "    ent1 = outcome_entropy(data1)\n",
    "\n",
    "    # Compute weights\n",
    "    w0 = data0.shape[0] / (data0.shape[0] + data1.shape[0])\n",
    "    w1 = data1.shape[0] / (data0.shape[0] + data1.shape[0])\n",
    "\n",
    "    # Return result\n",
    "    return ent0 * w0 + ent1 * w1\n",
    "\n",
    "split_entropy(data0, data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Ex. 2.3.4**: Find the optimal split threshold. Write a function called `optimal_threshold(data, feature)`\n",
    "that takes as input your data and a feature, and loops over all possible splits for a feature such as to find and return the minimum split entropy and associated threshold. Execute it for 'worst perimeter' does this match up with your results from 2.3.2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T07:21:47.028899Z",
     "start_time": "2020-02-17T07:21:46.420655Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105.9, 0.39064823727530884)"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def optimal_threshold(data, feature):\n",
    "    return min(\n",
    "        [\n",
    "            (\n",
    "                thr,\n",
    "                split_entropy(*split_data_on(data, feature, thr))\n",
    "            )\n",
    "            for thr in data[feature]\n",
    "        ],\n",
    "        key=lambda kv: kv[1]\n",
    "    )\n",
    "\n",
    "optimal_threshold(data_features, 'worst perimeter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Ex. 2.3.5**: Now you have (1) a function that finds the best feature to split on, given dataframe of data, and (2) another function that computes the threshold at which to split it into two new subsets. Implement the decision tree mechanism, and print the maximum entropy path.\n",
    ">1. Implement the following pseudocode and print the output:<br><br>\n",
    ">Step 0. Initially, set `data = data_features`.<br>\n",
    ">Step 1. Find the feature that gives the lowest split entropy for `data` (use `best_feature`). Print the name of the feature.<br>\n",
    ">Step 2. Split `data` *on the optimal threshold* of that feature, to produce `data0` and `data1` (use `optimal_threshold` to find the optimal threshold and then use `split_data_on` to actually split it). Print the entropy of each, as well as their weighted avg. entropy (i.e. the split entropy).<br>\n",
    ">Step 3. Overwrite the `data` variable with either `data0` or `data1`, depending on which has the highest entropy.<br>\n",
    ">Step 4. Stop if there are less than 5 datapoints in `data`. Otherwise start over from 1.<br><br>\n",
    ">My output looks [like this](https://github.com/abjer/sds_eml_2020/blob/master/material/session_2/solution_2.3.5.1.png) for the first five splits.<br><br>\n",
    ">\n",
    ">2. Comment on decision path your code takes: How many splits are there? Does average entropy always decrease? Anything else worth commenting on?\n",
    ">3. Train a `sklearn.tree.DecisionTreeClassifier` classifier on the dataset. Initiate the classifier with `criterion='entropy'`. What are the most important features of this classifier? How does this line up with the order of splits you just printed (a comment is fine)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T07:53:25.799562Z",
     "start_time": "2020-02-17T07:53:24.820349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 0: worst perimeter\n",
      "------------------------\n",
      "    data0:\n",
      "        size:    345\n",
      "        entropy: 0.2833107377061481\n",
      "    data1:\n",
      "        size:    224\n",
      "        entropy: 0.5559671540224538\n",
      "    --> average entropy: 0.39064823727530884\n",
      "\n",
      "Split 1: mean concave points\n",
      "----------------------------\n",
      "    data0:\n",
      "        size:    34\n",
      "        entropy: 0.9596868937742169\n",
      "    data1:\n",
      "        size:    190\n",
      "        entropy: 0.25186284771956513\n",
      "    --> average entropy: 0.35930042613857477\n",
      "\n",
      "Split 2: worst texture\n",
      "----------------------\n",
      "    data0:\n",
      "        size:    16\n",
      "        entropy: 0.3372900666170139\n",
      "    data1:\n",
      "        size:    18\n",
      "        entropy: 0.9182958340544896\n",
      "    --> average entropy: 0.6448813552603834\n",
      "\n",
      "Split 3: concavity error\n",
      "------------------------\n",
      "    data0:\n",
      "        size:    14\n",
      "        entropy: 0.5916727785823275\n",
      "    data1:\n",
      "        size:    4\n",
      "        entropy: -0.0\n",
      "    --> average entropy: 0.4601899388973658\n",
      "\n",
      "Split 4: concave points error\n",
      "-----------------------------\n",
      "    data0:\n",
      "        size:    12\n",
      "        entropy: -0.0\n",
      "    data1:\n",
      "        size:    2\n",
      "        entropy: -0.0\n",
      "    --> average entropy: -0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# step 0: Make new variable `data`\n",
    "data = data_features.copy() \n",
    "\n",
    "i = 0\n",
    "while True:\n",
    "    \n",
    "    # step 4\n",
    "    if len(data) < 5:\n",
    "        break\n",
    "        \n",
    "    # step 1\n",
    "    split_feature = best_feature(data)\n",
    "    \n",
    "    # step 2a\n",
    "    thr, ent = optimal_threshold(data, split_feature)\n",
    "    \n",
    "    # step 2b\n",
    "    data0, data1 = split_data_on(data, split_feature, thr)\n",
    "\n",
    "    # step 3\n",
    "    ent0 = outcome_entropy(data0)\n",
    "    ent1 = outcome_entropy(data1)\n",
    "    \n",
    "    # Print output\n",
    "    print(f\"Split {i}: {split_feature}\")\n",
    "    print(\"-\" * len(f\"Split {i}: {split_feature}\"))\n",
    "    print(\"    data0:\")\n",
    "    print(f\"        size:    {len(data0)}\")\n",
    "    print(f\"        entropy: {ent0}\")\n",
    "    print(\"    data1:\")\n",
    "    print(f\"        size:    {len(data1)}\")\n",
    "    print(f\"        entropy: {ent1}\")\n",
    "    print(f\"    --> average entropy: {ent}\\n\")\n",
    "    \n",
    "    # step 3 (continued)\n",
    "    if ent0 > ent1:\n",
    "        data = data0\n",
    "    else:\n",
    "        data = data1\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** It tends to shave off a high-entropy chunk and a small-entropy chunk. If the high-entropy chunk were always bigger than\n",
    "the small entropy chunk, then we would likely see split entropy decrease monotously, but already at split 1 we see\n",
    "that the small chunk has the highest entropy, and as such we continue splitting on that. Because this happens\n",
    "we end up having to split a very small chunk of data, and potentially, this is not easily split to the average split\n",
    "entropy rises again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T07:24:49.891193Z",
     "start_time": "2020-02-17T07:24:49.873746Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('worst perimeter', 0.6858889407411874),\n",
       " ('worst concave points', 0.1007829871346577),\n",
       " ('worst texture', 0.05690144222889103),\n",
       " ('worst smoothness', 0.04462567019858399),\n",
       " ('area error', 0.01759705469311716),\n",
       " ('worst symmetry', 0.017287741269216263),\n",
       " ('smoothness error', 0.01397028994778079),\n",
       " ('mean radius', 0.013472884788102825),\n",
       " ('worst area', 0.012512713022021418),\n",
       " ('mean smoothness', 0.011973493890974152)]"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# train model\n",
    "model = DecisionTreeClassifier(criterion='entropy')\n",
    "model.fit(data_features.drop(\"benign\", axis=1), data_features.benign)\n",
    "\n",
    "# print feature importances\n",
    "sorted(zip(data_features.columns[:-1], model.feature_importances_), key=lambda kv: kv[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** The decision tree heavily overweights the importance of the first feature it splits on, but we see it\n",
    "chooses the same one as we do. For the remainder, there are differences, of course because we only split on the most\n",
    "entropous subset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Challenge!**: Finish the implementation and write a piece of code that makes all splits at each level, level-for-level for 4 levels.\n",
    "You can store the tree as a nested dictionary with a structure like:\n",
    ">\n",
    ">        mytree = {\n",
    ">            'majority': 1,\n",
    ">            'feature': 'worst perimeter',\n",
    ">            'threshold': 105.9,\n",
    ">            'leafs': {\n",
    ">                {\n",
    ">                    'less than or equal to': {\n",
    ">                        'majority': 1,\n",
    ">                        'feature': 'mean concave points',\n",
    ">                        'threshold': 0.05102,\n",
    ">                        'leafs': {...}\n",
    ">                    },\n",
    ">                    'greater than': {\n",
    ">                        'majority': 0,\n",
    ">                        'feature': 'mean concave points',\n",
    ">                        'threshold': 0.04835,\n",
    ">                        'leafs': {...}\n",
    ">                    }\n",
    ">                }\n",
    ">            }\n",
    ">        }\n",
    ">\n",
    "> ... which will allow you to write another bit of code that takes an arbitrary data point and produces a prediction.\n",
    ">\n",
    "> *Note: Implementing and fitting a classifier manually is **no small accomplishment**! If you manage, you can easily add it to your Github\n",
    "portfolio and brag about it in a Medium blog post (if written well will probably get picked up by 'Towards\n",
    "Data Science' or similar), on LinkedIn or Twitter. To quote Edison: \"Opportunity is missed by most people because it is dressed in overalls and looks like work.\"*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}